@article{2015RollingElementBearing,
  title = {Rolling Element Bearing Diagnostics Using the {{Case Western Reserve University}} Data: {{A}} Benchmark Study},
  shorttitle = {Rolling Element Bearing Diagnostics Using the {{Case Western Reserve University}} Data},
  year = 2015,
  month = dec,
  journal = {Mechanical Systems and Signal Processing},
  volume = {64},
  pages = {100--131},
  publisher = {Academic Press},
  issn = {0888-3270},
  doi = {10.1016/J.YMSSP.2015.04.021},
  urldate = {2025-11-14},
  abstract = {(DOI: 10.1016/J.YMSSP.2015.04.021) This article is published in Mechanical Systems and Signal Processing. The article was published on 01 Dec 2015.},
  langid = {english},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/ECSKSSTG/rolling-element-bearing-diagnostics-using-the-case-western-1j7d4ksrgw.html}
}

@techreport{a&d2020OpenSourceIndustrial,
  title = {Open Source in Industrial Automation},
  author = {{A\&D}},
  year = 2020,
  institution = {PLCnext Community}
}

@inproceedings{ahmatshin2024MinibatchKMeansClustering,
  title = {Mini-Batch {{K-Means}}++ {{Clustering Initialization}}},
  booktitle = {Mathematical {{Optimization Theory}} and {{Operations Research}}: {{Recent Trends}}},
  author = {Ahmatshin, Farid and Kazakovtsev, Lev},
  editor = {Eremeev, Anton and Khachay, Michael and Kochetov, Yury and Mazalov, Vladimir and Pardalos, Panos},
  year = 2024,
  pages = {293--307},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-73365-9_20},
  abstract = {Fast algorithms for clustering large and ultra-large volumes of data are in demand in various fields, for example, vector databases. The k-means algorithm remains the most popular, however, it is extremely dependent on the initialization method. K-means++ is a well-established procedure for selecting initial cluster centers (centroids) for the k-means algorithm. In this work, we present a new algorithm capable of solving the k-means++ initialization problem for obtaining a good initial solution. The well-known k-means++ algorithm works well for data sets of N data vectors in a d-dimensional space when performing a single pass through the input data in O(k) iterations, and each iteration is characterized by complexity O(Ndk), where k is the number of centroids (clusters). So, the total execution time is \$\$O(Ndk\textasciicircum 2)\$\$O(Ndk2). Since k-means++ requires k passes through the data to initialize, it does not scale well to large data sets. We propose the Mini-batch K-means++ algorithm with a single pass through the data and a total expected execution time of \$\$O(dk(b+\textbackslash log B))\$\$O(dk(b+logB)), where B is the number of batches of data, and b is the number of data vectors in one batch, \$\$N \textbackslash le Bb\$\$N{$\leq$}Bb. The higher comparative efficiency of the new Mini-batch K-means++ algorithm for big data is shown by the experiment. The minimum amount of memory resources for the algorithm to run is expected at \$\$B=n\textasciicircum\textbraceleft 1/2\textbraceright\$\$B=n1/2with a non-optimal execution time of \$\$O(dk(b+\textbackslash log B))\$\$O(dk(b+logB)). In the optimal scenario for running a new algorithm, for \$\$2\textasciicircum w\$\$2wdata vectors, the expected time expenditure is O(dkw). It is shown that the quality of solutions is not inferior to the classical k-means++.},
  isbn = {978-3-031-73365-9},
  langid = {english},
  keywords = {clustering,k-Means++,Mini-batch k-Means},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/2YMLQF5R/Ahmatshin and Kazakovtsev - 2024 - Mini-batch K-Means++ Clustering Initialization.pdf}
}

@techreport{algorithmia20202020StateEnterprise,
  title = {2020 State of Enterprise Machine Learning},
  author = {{Algorithmia}},
  year = 2020
}

@article{alqoud2022Industry40Systematic,
  title = {Industry 4.0: A Systematic Review of Legacy Manufacturing System Digital Retrofitting},
  author = {Alqoud, A. and {Milisavljevic-Syed}, J. and Allen, J.K.},
  year = 2022,
  journal = {Manufacturing Review},
  volume = {9},
  number = {32},
  pages = {1--21}
}

@inproceedings{amruthnath2018ResearchStudyUnsupervised,
  title = {A Research Study on Unsupervised Machine Learning Algorithms for Early Fault Detection in Predictive Maintenance},
  booktitle = {2018 5th {{International Conference}} on {{Industrial Engineering}} and {{Applications}} ({{ICIEA}})},
  author = {Amruthnath, Nagdev and Gupta, Tarun},
  year = 2018,
  month = apr,
  pages = {355--361},
  doi = {10.1109/IEA.2018.8387124},
  urldate = {2025-11-14},
  abstract = {The area of predictive maintenance has taken a lot of prominence in the last couple of years due to various reasons. With new algorithms and methodologies growing across different learning methods, it has remained a challenge for industries to adopt which method is fit, robust and provide most accurate detection. Fault detection is one of the critical components of predictive maintenance; it is very much needed for industries to detect faults early and accurately. In a production environment, to minimize the cost of maintenance, sometimes it is required to build a model with minimal or no historical data. In such cases, unsupervised learning would be a better option model building. In this paper, we have chosen a simple vibration data collected from an exhaust fan, and have fit different unsupervised learning algorithms such as PCA T2 statistic, Hierarchical clustering, K-Means, Fuzzy C-Means clustering and model-based clustering to test its accuracy, performance, and robustness. In the end, we have proposed a methodology to benchmark different algorithms and choosing the final model.},
  keywords = {Clustering algorithms,fault detection,Fault detection,just in time,machine learning,Machine learning algorithms,manufacturing,predictive maintenance,Predictive maintenance,Principal component analysis,Vibrations},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/WQ47FUME/8387124.html}
}

@misc{AnomalyDetectionAsset,
  title = {Anomaly {{Detection}} in {{Asset Degradation Process Using Variational Autoencoder}} and {{Explanations}}},
  urldate = {2025-11-14},
  howpublished = {https://www.mdpi.com/1424-8220/22/1/291},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/XCWQXZTL/291.html}
}

@techreport{azion2023CloudComputingEdge,
  title = {Cloud Computing or Edge Computing: {{Cost}} Comparison},
  author = {{Azion}},
  year = 2023
}

@inproceedings{baldridge2004ActiveLearningTotal,
  title = {Active Learning and the Total Cost of Annotation},
  booktitle = {Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing ({{EMNLP}})},
  author = {Baldridge, J. and Osborne, M.},
  year = 2004,
  pages = {1--8}
}

@inproceedings{bengio2009CurriculumLearning,
  title = {Curriculum Learning},
  booktitle = {Proceedings of the 26th {{Annual International Conference}} on {{Machine Learning}}},
  author = {Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  year = 2009,
  month = jun,
  pages = {41--48},
  publisher = {ACM},
  address = {Montreal Quebec Canada},
  doi = {10.1145/1553374.1553380},
  urldate = {2025-11-14},
  abstract = {Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them "curriculum learning". In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).},
  isbn = {978-1-60558-516-1},
  langid = {english}
}

@inproceedings{cai2020tinytl,
  title = {{{TinyTL}}: {{Reduce}} Memory, Not Parameters for Efficient on-Device Learning},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Cai, Han and Gan, Chuang and Zhu, Ligeng and Han, Song},
  year = 2020,
  volume = {33}
}

@inproceedings{cao2006DensityBasedClusteringEvolving,
  title = {Density-{{Based Clustering}} over an {{Evolving Data Stream}} with {{Noise}}},
  author = {Cao, Feng and Ester, Martin and Qian, Weining and Zhou, Aoying},
  year = 2006,
  month = apr,
  volume = {2006},
  doi = {10.1137/1.9781611972764.29},
  abstract = {Clustering is an important task in mining evolving data streams. Beside the limited memory and one-pass con- straints, the nature of evolving data streams implies the following requirements for stream clustering: no as- sumption on the number of clusters, discovery of clus- ters with arbitrary shape and ability to handle outliers. While a lot of clustering algorithms for data streams have been proposed, they oer no solution to the combi- nation of these requirements. In this paper, we present DenStream, a new approach for discovering clusters in an evolving data stream. The "dense" micro-cluster (named core-micro-cluster) is introduced to summarize the clusters with arbitrary shape, while the potential core-micro-cluster and outlier micro-cluster structures are proposed to maintain and distinguish the potential clusters and outliers. A novel pruning strategy is de- signed based on these concepts, which guarantees the precision of the weights of the micro-clusters with lim- ited memory. Our performance study over a number of real and synthetic data sets demonstrates the eective- ness and eciency},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/TMCDNCFQ/Cao et al. - 2006 - Density-Based Clustering over an Evolving Data Stream with Noise.pdf}
}

@techreport{comptia2024TechWorkforce,
  title = {Tech Workforce Report 2024},
  author = {{CompTIA}},
  year = 2024
}

@misc{david2021TensorFlowLiteMicro,
  title = {{{TensorFlow Lite Micro}}: {{Embedded Machine Learning}} on {{TinyML Systems}}},
  shorttitle = {{{TensorFlow Lite Micro}}},
  author = {David, Robert and Duke, Jared and Jain, Advait and Reddi, Vijay Janapa and Jeffries, Nat and Li, Jian and Kreeger, Nick and Nappier, Ian and Natraj, Meghna and Regev, Shlomi and Rhodes, Rocky and Wang, Tiezhen and Warden, Pete},
  year = 2021,
  month = mar,
  number = {arXiv:2010.08678},
  eprint = {2010.08678},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2010.08678},
  urldate = {2025-11-14},
  abstract = {Deep learning inference on embedded devices is a burgeoning field with myriad applications because tiny embedded devices are omnipresent. But we must overcome major challenges before we can benefit from this opportunity. Embedded processors are severely resource constrained. Their nearest mobile counterparts exhibit at least a 100 -- 1,000x difference in compute capability, memory availability, and power consumption. As a result, the machine-learning (ML) models and associated ML inference framework must not only execute efficiently but also operate in a few kilobytes of memory. Also, the embedded devices' ecosystem is heavily fragmented. To maximize efficiency, system vendors often omit many features that commonly appear in mainstream systems, including dynamic memory allocation and virtual memory, that allow for cross-platform interoperability. The hardware comes in many flavors (e.g., instruction-set architecture and FPU support, or lack thereof). We introduce TensorFlow Lite Micro (TF Micro), an open-source ML inference framework for running deep-learning models on embedded systems. TF Micro tackles the efficiency requirements imposed by embedded-system resource constraints and the fragmentation challenges that make cross-platform interoperability nearly impossible. The framework adopts a unique interpreter-based approach that provides flexibility while overcoming these challenges. This paper explains the design decisions behind TF Micro and describes its implementation details. Also, we present an evaluation to demonstrate its low resource requirement and minimal run-time performance overhead.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/AREZWTIZ/David et al. - 2021 - TensorFlow Lite Micro Embedded Machine Learning on TinyML Systems.pdf;/home/kzlee/snap/zotero-snap/common/Zotero/storage/L3XIRJ3W/2010.html}
}

@inproceedings{fails2003InteractiveMachineLearning,
  title = {Interactive Machine Learning},
  author = {Fails, Jerry and Olsen, Dan},
  year = 2003,
  month = jan,
  pages = {39},
  doi = {10.1145/604050.604056},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/HLMSJXA7/Fails and Olsen - 2003 - Interactive machine learning.pdf}
}

@article{flores2025EnhancedVectorQuantization,
  title = {Enhanced {{Vector Quantization}} for {{Embedded Machine Learning}}: {{A Post-Training Approach With Incremental Clustering}}},
  shorttitle = {Enhanced {{Vector Quantization}} for {{Embedded Machine Learning}}},
  author = {Flores, Thommas K. S. and Medeiros, Morsinaldo and Silva, Marianne and Costa, Daniel G. and Silva, Ivanovitch},
  year = 2025,
  journal = {IEEE Access},
  volume = {13},
  pages = {17440--17456},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2025.3532849},
  urldate = {2025-11-06},
  abstract = {TinyML enables the deployment of Machine Learning (ML) models on resource-constrained devices, addressing a growing need for efficient, low-power AI solutions. However, significant challenges remain due to strict memory, processing, and energy limitations. This study introduces a novel method to optimize Post-Training Quantization (PTQ), a widely used technique for reducing model size, by integrating Vector Quantization (VQ) with incremental clustering. While VQ is a technique that reduces model size by grouping similar parameters, incremental clustering, implemented via the AutoCloud K-Fixed algorithm, preserves accuracy during compression. This combined approach was validated on an automotive dataset predicting CO2 emissions from vehicle sensor measurements such as mass air flow, intake pressure, temperature, and speed. The model was quantized and deployed on Macchina A0 hardware, demonstrating over 90\% compression with negligible accuracy loss. Results show improved performance and deployment efficiency, showcasing the potential of this combined technique for real-world embedded applications.},
  keywords = {Accuracy,Adaptation models,Automotive engineering,automotive sensors,Clustering algorithms,Computational efficiency,Computational modeling,Data models,Embedded systems,pollution,post-training quantization,Training,vector quantization,Vector quantization},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/3KEZ43XG/Flores et al. - 2025 - Enhanced Vector Quantization for Embedded Machine Learning A Post-Training Approach With Incrementa.pdf}
}

@article{hicks2021MbkmeansFastClustering,
  title = {Mbkmeans: {{Fast}} Clustering for Single Cell Data Using Mini-Batch k-Means},
  shorttitle = {Mbkmeans},
  author = {Hicks, Stephanie C. and Liu, Ruoxi and Ni, Yuwei and Purdom, Elizabeth and Risso, Davide},
  year = 2021,
  month = jan,
  journal = {PLOS Computational Biology},
  volume = {17},
  number = {1},
  pages = {e1008625},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008625},
  urldate = {2025-11-06},
  abstract = {Single-cell RNA-Sequencing (scRNA-seq) is the most widely used high-throughput technology to measure genome-wide gene expression at the single-cell level. One of the most common analyses of scRNA-seq data detects distinct subpopulations of cells through the use of unsupervised clustering algorithms. However, recent advances in scRNA-seq technologies result in current datasets ranging from thousands to millions of cells. Popular clustering algorithms, such as k-means, typically require the data to be loaded entirely into memory and therefore can be slow or impossible to run with large datasets. To address this problem, we developed the mbkmeans R/Bioconductor package, an open-source implementation of the mini-batch k-means algorithm. Our package allows for on-disk data representations, such as the common HDF5 file format widely used for single-cell data, that do not require all the data to be loaded into memory at one time. We demonstrate the performance of the mbkmeans package using large datasets, including one with 1.3 million cells. We also highlight and compare the computing performance of mbkmeans against the standard implementation of k-means and other popular single-cell clustering methods. Our software package is available in Bioconductor at https://bioconductor.org/packages/mbkmeans.},
  langid = {english},
  keywords = {Algorithms,Clustering algorithms,Computer hardware,Computer software,Gene expression,Machine learning algorithms,Principal component analysis,Simulation and modeling},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/V6W8Y9BP/Hicks et al. - 2021 - mbkmeans Fast clustering for single cell data using mini-batch k-means.pdf}
}

@techreport{internationaldatacorporation2023BusinessOpportunityAI,
  title = {The Business Opportunity of {{AI}}},
  author = {{International Data Corporation} and {Microsoft}},
  year = 2023,
  number = {US51315823}
}

@techreport{iotanalytics2025IoTEdgeComputing,
  title = {{{IoT}} Edge Computing -- What It Is and How It Is Becoming More Intelligent},
  author = {{IoT Analytics}},
  year = 2025
}

@article{jakubowski2021AnomalyDetectionAsset,
  title = {Anomaly {{Detection}} in {{Asset Degradation Process Using Variational Autoencoder}} and {{Explanations}}},
  author = {Jakubowski, Jakub and Stanisz, Przemys{\l}aw and Bobek, Szymon and Nalepa, Grzegorz J.},
  year = 2021,
  month = dec,
  journal = {Sensors (Basel, Switzerland)},
  volume = {22},
  number = {1},
  pages = {291},
  issn = {1424-8220},
  doi = {10.3390/s22010291},
  urldate = {2025-11-14},
  abstract = {Development of predictive maintenance (PdM) solutions is one of the key aspects of Industry 4.0. In recent years, more attention has been paid to data-driven techniques, which use machine learning to monitor the health of an industrial asset. The major issue in the implementation of PdM models is a lack of good quality labelled data. In the paper we present how unsupervised learning using a variational autoencoder may be used to monitor the wear of rolls in a hot strip mill, a part of a steel-making site. As an additional benchmark we use a simulated turbofan engine data set provided by NASA. We also use explainability methods in order to understand the model's predictions. The results show that the variational autoencoder slightly outperforms the base autoencoder architecture in anomaly detection tasks. However, its performance on the real use-case does not make it a production-ready solution for industry and should be a matter of further research. Furthermore, the information obtained from the explainability model can increase the reliability of the proposed artificial intelligence-based solution.},
  pmcid = {PMC8749861},
  pmid = {35009832},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/QI56YSPX/Jakubowski et al. - 2021 - Anomaly Detection in Asset Degradation Process Using Variational Autoencoder and Explanations.pdf}
}

@article{journalofcloudcomputing2016CriticalAnalysisVendor,
  title = {Critical Analysis of Vendor Lock-in and Its Impact on Cloud Computing Migration: A Business Perspective},
  author = {{Journal of Cloud Computing}},
  year = 2016,
  journal = {Journal of Cloud Computing},
  publisher = {SpringerOpen}
}

@techreport{kellerexecutivesearch2025AIMachinelearningTalent,
  title = {{{AI}} \& Machine-Learning Talent Gap 2025},
  author = {{Keller Executive Search}},
  year = 2025
}

@misc{lai2018CMSISNNEfficientNeural,
  title = {{{CMSIS-NN}}: {{Efficient Neural Network Kernels}} for {{Arm Cortex-M CPUs}}},
  shorttitle = {{{CMSIS-NN}}},
  author = {Lai, Liangzhen and Suda, Naveen and Chandra, Vikas},
  year = 2018,
  month = jan,
  number = {arXiv:1801.06601},
  eprint = {1801.06601},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1801.06601},
  urldate = {2025-11-06},
  abstract = {Deep Neural Networks are becoming increasingly popular in always-on IoT edge devices performing data analytics right at the source, reducing latency as well as energy consumption for data communication. This paper presents CMSIS-NN, efficient kernels developed to maximize the performance and minimize the memory footprint of neural network (NN) applications on Arm Cortex-M processors targeted for intelligent IoT edge devices. Neural network inference based on CMSIS-NN kernels achieves 4.6X improvement in runtime/throughput and 4.9X improvement in energy efficiency.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Mathematical Software,Computer Science - Neural and Evolutionary Computing},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/338FHD4X/1801.html}
}

@inproceedings{lin2022mcunetv3,
  title = {On-Device Training under {{256KB}} Memory},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Lin, Ji and Zhu, Ligeng and Chen, Wei-Ming and Wang, Wei-Chen and Gan, Chuang and Han, Song},
  year = 2022,
  volume = {35}
}

@inproceedings{liu2008IsolationForest,
  title = {Isolation {{Forest}}},
  booktitle = {2008 {{Eighth IEEE International Conference}} on {{Data Mining}}},
  author = {Liu, Fei Tony and Ting, Kai Ming and Zhou, Zhi-Hua},
  year = 2008,
  month = dec,
  pages = {413--422},
  issn = {2374-8486},
  doi = {10.1109/ICDM.2008.17},
  urldate = {2025-11-14},
  abstract = {Most existing model-based approaches to anomaly detection construct a profile of normal instances, then identify instances that do not conform to the normal profile as anomalies. This paper proposes a fundamentally different model-based method that explicitly isolates anomalies instead of profiles normal points. To our best knowledge, the concept of isolation has not been explored in current literature. The use of isolation enables the proposed method, iForest, to exploit sub-sampling to an extent that is not feasible in existing methods, creating an algorithm which has a linear time complexity with a low constant and a low memory requirement. Our empirical evaluation shows that iForest performs favourably to ORCA, a near-linear time complexity distance-based method, LOF and random forests in terms of AUC and processing time, and especially in large data sets. iForest also works well in high dimensional problems which have a large number of irrelevant attributes, and in situations where training set does not contain any anomalies.},
  keywords = {anomaly detection,Application software,Astronomy,binary trees,Constraint optimization,Credit cards,Data mining,Detectors,Information technology,isolation forest,Isolation technology,Laboratories,model based,novelty detection,outlier detection,Performance evaluation},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/B9V9PI39/4781136.html}
}

@article{mahato2025DairyDigiDEdgeCloud,
  title = {Dairy {{DigiD}}: {{An Edge-Cloud Framework}} for {{Real-Time Cattle Biometrics}} and {{Health Classification}}},
  shorttitle = {Dairy {{DigiD}}},
  author = {Mahato, Shubhangi and Neethirajan, Suresh},
  year = 2025,
  month = sep,
  journal = {AI},
  volume = {6},
  number = {9},
  pages = {196},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2673-2688},
  doi = {10.3390/ai6090196},
  urldate = {2025-11-06},
  abstract = {Digital livestock farming faces a critical deployment challenge: bridging the gap between cutting-edge AI algorithms and practical implementation in resource-constrained agricultural environments. While deep learning models demonstrate exceptional accuracy in laboratory settings, their translation to operational farm systems remains limited by computational constraints, connectivity issues, and user accessibility barriers. Dairy DigiD addresses these challenges through a novel edge-cloud AI framework integrating YOLOv11 object detection with DenseNet121 physiological classification for cattle monitoring. The system employs YOLOv11-nano architecture optimized through INT8 quantization (achieving 73\% model compression with {$<$}1\% accuracy degradation) and TensorRT acceleration, enabling 24 FPS real-time inference on NVIDIA Jetson edge devices while maintaining 94.2\% classification accuracy. Our key innovation lies in intelligent confidence-based offloading: routine detections execute locally at the edge, while ambiguous cases trigger cloud processing for enhanced accuracy. An entropy-based active learning pipeline using Roboflow reduces the annotation overhead by 65\% while preserving 97\% of the model performance. The Gradio interface democratizes system access, reducing technician training requirements by 84\%. Comprehensive validation across ten commercial dairy farms in Atlantic Canada demonstrates robust performance under diverse environmental conditions (seasonal, lighting, weather variations). The framework achieves mAP@50 of 0.947 with balanced precision-recall across four physiological classes, while consuming 18\% less energy than baseline implementations through attention-based optimization. Rather than proposing novel algorithms, this work contributes a systems-level integration methodology that transforms research-grade AI into deployable agricultural solutions. Our open-source framework provides a replicable blueprint for precision livestock farming adoption, addressing practical barriers that have historically limited AI deployment in agricultural settings.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {AI framework,cattle identification,computer vision,deep learning,edge computing,human-AI interaction,model optimization,precision livestock farming,sustainable agriculture,YOLOv11},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/YVA7HUJ3/Mahato and Neethirajan - 2025 - Dairy DigiD An Edge-Cloud Framework for Real-Time Cattle Biometrics and Health Classification.pdf}
}

@techreport{maintainx20252025StateIndustrial,
  title = {The 2025 State of Industrial Maintenance Report},
  author = {{MaintainX}},
  year = 2025
}

@inproceedings{martin-del-campo2020UnsupervisedRankingOutliers,
  title = {Unsupervised Ranking of Outliers in Wind Turbines via Isolation Forest with Dictionary Learning},
  booktitle = {5th {{European Conference}} of the {{Prognostics}} and {{Health Management}} ({{PHM}}) {{Society}} ({{PHME}} 2020), 27-31 {{July}}, 2020, {{Virtual Conference}}},
  author = {{Martin-del-Campo}, Sergio and {Al-Kahwati}, Kammal},
  year = 2020,
  publisher = {PHM Society},
  urldate = {2025-11-14},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/QYXRI3F2/Martin-del-Campo and Al-Kahwati - 2020 - Unsupervised ranking of outliers in wind turbines via isolation forest with dictionary learning.pdf}
}

@techreport{mckinsey&company2021Industry40Adoption,
  title = {Industry 4.0 Adoption with the Right Focus},
  author = {{McKinsey \& Company}},
  year = 2021,
  month = oct
}

@misc{moring2024YouCantHire,
  title = {You {{Can}}'t {{Hire Your Way}} to {{Model Alignment}}},
  author = {Moring, Marc},
  year = 2024,
  month = dec,
  urldate = {2025-11-06},
  abstract = {Why the Global AI talent shortage Is undermining enterprise model alignment, and what you can do instead},
  howpublished = {https://blog.collinear.ai/p/ai-talent-wars},
  langid = {english},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/492D2FF6/ai-talent-wars.html}
}

@article{mosqueira-rey2023HumanintheloopMachineLearning,
  title = {Human-in-the-Loop Machine Learning: A State of the Art},
  author = {{Mosqueira-Rey}, E. and others},
  year = 2023,
  journal = {Artificial Intelligence Review},
  volume = {56},
  pages = {3005--3054},
  doi = {10.1007/s10462-022-10246-w}
}

@inproceedings{mousavi2022UNSUPERVISEDCONDITIONMONITORING,
  title = {{{UNSUPERVISED CONDITION MONITORING OF STRUCTURES USING VMD AND ISOLATION FOREST}}},
  author = {Mousavi, Mohsen and Gandomi, Amir},
  year = 2022,
  month = mar,
  doi = {10.12783/shm2021/36300},
  abstract = {In this paper, an unsupervised condition monitoring of civil infrastructures under environmental and operational variations is proposed. To this end, a couple of the lowest natural frequency signals of the structure recorded over a long period of time are studied for damage. Most of the existing techniques are supervised and require baseline information from the healthy state of the structure. In this paper, however, we explore the possibility of performing unsupervised condition monitoring using Isolation Forest (IF) as a well-known unsupervised machine learning approach. We show that a preprocessing of the frequency signals using the Variational Mode Decomposition (VMD) algorithm plays a key role in the success of the IF algorithm in the unsupervised condition monitoring of structures. To investigate the performance of the proposed method, the benchmark problem of the Z24 bridge is studied in this paper. The results show that the proposed methodology stays successful in most of the cases but at a period of very cold temperature where a nonlinear relationship between the frequencies and temperature presents.}
}

@techreport{nor-calcontrols2023DeterminingSolarPV,
  title = {Determining Solar {{PV SCADA}} System Costs: {{Upfront}} and Long-Term Considerations},
  author = {{Nor-Cal Controls}},
  year = 2023
}

@techreport{op-tecsystems2024HowBuyAutomation,
  title = {How to Buy Automation without Getting Locked into Vendor Ecosystems},
  author = {{Op-tec Systems}},
  year = 2024
}

@techreport{osie2020OpenSourceIndustrial,
  title = {Open Source Industrial Edge ({{OSIE}}): {{Industrial}} Edge as a Service},
  author = {{OSIE Project Consortium}},
  year = 2020,
  month = may
}

@techreport{osieprojectconsortium2018OpenSourceIndustrial,
  title = {Open Source Industrial Edge ({{OSIE}}): {{Industrial}} Edge as a Service},
  author = {{OSIE Project Consortium}},
  year = 2018
}

@techreport{oxmaint2025PredictiveMaintenanceManufacturing,
  title = {Predictive Maintenance in Manufacturing: {{ROI}} Guide \& Implementation Steps},
  author = {{OXMaint}},
  year = 2025
}

@techreport{pwc2018PredictiveMaintenance40,
  title = {Predictive Maintenance 4.0: {{Beyond}} the Hype - {{PdM}} 4.0 Delivers Results},
  author = {{PwC} and {Mainnovation}},
  year = 2018,
  month = sep
}

@inproceedings{qian2019DistributedActiveLearning,
  title = {Distributed {{Active Learning Strategies}} on {{Edge Computing}}},
  author = {Qian, Jia and Gochhayat, Sarada and Hansen, Lars},
  year = 2019,
  month = jun,
  pages = {221--226},
  doi = {10.1109/CSCloud/EdgeCom.2019.00029},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/FEVYVSAV/Qian et al. - 2019 - Distributed Active Learning Strategies on Edge Computing.pdf}
}

@inproceedings{ren2021TinyOLTinyMLOnlinelearning,
  title = {{{TinyOL}}: {{TinyML}} with Online-Learning on Microcontrollers},
  booktitle = {2021 International Joint Conference on Neural Networks ({{IJCNN}})},
  author = {Ren, Haoyu and Anicic, Darko and Runkler, Thomas A.},
  year = 2021,
  pages = {1--8},
  publisher = {IEEE},
  doi = {10.1109/IJCNN52387.2021.9533927}
}

@techreport{rockwellautomation2023EdgeCloudWhats,
  title = {Edge or Cloud: {{What}}'s Best for Manufacturers?},
  author = {{Rockwell Automation}},
  year = 2023
}

@article{rosa2024benchmarking,
  title = {Benchmarking Deep Learning Models for Bearing Fault Diagnosis Using the {{CWRU}} Dataset: {{A}} Multi-Label Approach},
  author = {Rosa, R.K. and Braga, D. and Silva, D.},
  year = 2024,
  journal = {arXiv preprint arXiv:2407.14625},
  eprint = {2407.14625},
  archiveprefix = {arXiv}
}

@article{sarita2022RETRACTEDPrincipalComponent,
  title = {{{RETRACTED}}: {{Principal}} Component Analysis Technique for Early Fault Detection},
  shorttitle = {{{RETRACTED}}},
  author = {Sarita, Kumari and Devarapalli, Ramesh and Kumar, Sanjeev and Malik, H. and Garc{\'i}a M{\'a}rquez, Fausto Pedro and Rai, Pankaj},
  year = 2022,
  month = jan,
  journal = {Journal of Intelligent \& Fuzzy Systems},
  volume = {42},
  number = {2},
  pages = {861--872},
  publisher = {SAGE Publications},
  issn = {1064-1246},
  doi = {10.3233/JIFS-189755},
  urldate = {2025-11-14},
  langid = {english},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/C8V53BDE/Sarita et al. - 2022 - RETRACTED Principal component analysis technique for early fault detection.pdf}
}

@inproceedings{shindler2011FastAccurateKmeans,
  title = {Fast and {{Accurate}} K-Means {{For Large Datasets}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Shindler, Michael and Wong, Alex and Meyerson, Adam},
  year = 2011,
  volume = {24},
  publisher = {Curran Associates, Inc.},
  urldate = {2025-11-14},
  abstract = {Clustering is a popular problem with many applications. We consider the k-means problem in the situation where the data is too large to be stored in main memory and must be accessed sequentially, such as from a disk, and where we must use as little memory as possible. Our algorithm is based on recent theoretical results, with significant improvements to make it practical. Our approach greatly simpli(cid:173) fies a recently developed algorithm, both in design and in analysis, and eliminates large constant factors in the approximation guarantee, the memory requirements, and the running time. We then incorporate approximate nearest neighbor search to compute k-means in o(nk) (where n is the number of data points; note that com(cid:173) puting the cost, given a solution, takes 8(nk) time). We show that our algorithm compares favorably to existing algorithms - both theoretically and experimentally, thus providing state-of-the-art performance in both theory and practice.},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/EQCPVM7P/Shindler et al. - 2011 - Fast and Accurate k-means For Large Datasets.pdf}
}

@article{smith2015RollingElementBearing,
  title = {Rolling Element Bearing Diagnostics Using the {{Case Western Reserve University}} Data: {{A}} Benchmark Study},
  shorttitle = {Rolling Element Bearing Diagnostics Using the {{Case Western Reserve University}} Data},
  author = {Smith, Wade A. and Randall, Robert B.},
  year = 2015,
  month = dec,
  journal = {Mechanical Systems and Signal Processing},
  volume = {64--65},
  pages = {100--131},
  issn = {08883270},
  doi = {10.1016/j.ymssp.2015.04.021},
  urldate = {2025-11-14},
  abstract = {Semantic Scholar extracted view of "Rolling element bearing diagnostics using the Case Western Reserve University data: A benchmark study" by W. Smith et al.},
  langid = {english}
}

@techreport{u.s.bureauoflaborstatistics2024OccupationalOutlookHandbook,
  title = {Occupational Outlook Handbook: {{Data}} Scientists},
  author = {{U.S. Bureau of Labor Statistics}},
  year = 2024
}

@article{wang2019CostawareActiveLearning,
  title = {Cost-Aware Active Learning for Named Entity Recognition in Clinical Text},
  author = {Wang, Q. and Wu, S. and Chen, Y. and others},
  year = 2019,
  journal = {Journal of the American Medical Informatics Association},
  volume = {26},
  number = {11},
  pages = {1314--1322},
  doi = {10.1093/jamia/ocz102}
}

@article{wei2019CostawareActiveLearning,
  title = {Cost-Aware Active Learning for Named Entity Recognition in Clinical Text},
  author = {Wei, Q. and Wu, S. and Chen, Y. and others},
  year = 2019,
  journal = {Journal of the American Medical Informatics Association},
  volume = {26},
  number = {11},
  pages = {1314--1322},
  doi = {10.1093/jamia/ocz102}
}

@article{worldjournalofadvancedengineeringtechnologyandsciences2025DemocratizingAIHow,
  title = {Democratizing {{AI}}: {{How AutoML}} Is Transforming Enterprise Machine Learning},
  author = {{World Journal of Advanced Engineering Technology and Sciences}},
  year = 2025,
  journal = {World Journal of Advanced Engineering Technology and Sciences},
  volume = {15},
  number = {01},
  pages = {701--708}
}

@article{yoo2023lite,
  title = {Lite and Efficient Deep Learning Model for Bearing Fault Diagnosis Using the {{CWRU}} Dataset},
  author = {Yoo, Y. and Baek, S.-W.},
  year = 2023,
  journal = {Sensors},
  volume = {23},
  number = {6},
  pages = {3157}
}

@inproceedings{zhang1996BIRCHEfficientData,
  title = {{{BIRCH}}: An Efficient Data Clustering Method for Very Large Databases},
  shorttitle = {{{BIRCH}}},
  booktitle = {Proceedings of the 1996 {{ACM SIGMOD}} International Conference on {{Management}} of Data  - {{SIGMOD}} '96},
  author = {Zhang, Tian and Ramakrishnan, Raghu and Livny, Miron},
  year = 1996,
  pages = {103--114},
  publisher = {ACM Press},
  address = {Montreal, Quebec, Canada},
  doi = {10.1145/233269.233324},
  urldate = {2025-11-14},
  abstract = {Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely studied problems in this area is the identification of clusters, or densely populated regions, in a multi-dimensional dataset. Prior work does not adequately address the problem of large datasets and minimization of I/O costs.This paper presents a data clustering method named BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), and demonstrates that it is especially suitable for very large databases. BIRCH incrementally and dynamically clusters incoming multi-dimensional metric data points to try to produce the best quality clustering with the available resources (i.e., available memory and time constraints). BIRCH can typically find a good clustering with a single scan of the data, and improve the quality further with a few additional scans. BIRCH is also the first clustering algorithm proposed in the database area to handle "noise" (data points that are not part of the underlying pattern) effectively.We evaluate BIRCH's time/space efficiency, data input order sensitivity, and clustering quality through several experiments. We also present a performance comparisons of BIRCH versus CLARANS, a clustering method proposed recently for large datasets, and show that BIRCH is consistently superior.},
  copyright = {https://www.acm.org/publications/policies/copyright\_policy\#Background},
  isbn = {978-0-89791-794-0},
  langid = {english},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/F6S8G2FQ/Zhang et al. - 1996 - BIRCH an efficient data clustering method for very large databases.pdf}
}

@inproceedings{zhang2020ArchitectureImplementationIndustrial,
  title = {Architecture and {{Implementation}} of {{Industrial Internet}} of {{Things}} ({{IIoT}}) {{Gateway}}},
  booktitle = {2020 {{IEEE}} 2nd {{International Conference}} on {{Civil Aviation Safety}} and {{Information Technology}} ({{ICCASIT}}},
  author = {Zhang, Yinfen and Sun, Wenfeng and Shi, Yuntao},
  year = 2020,
  month = oct,
  pages = {114--120},
  doi = {10.1109/ICCASIT50869.2020.9368773},
  urldate = {2025-11-14},
  abstract = {To solve the problems of complex industrial production data communication protocol and difficult communication between industrial equipment and cloud, an industrial internet of things (IIoT) gateway architecture is proposed. Firstly, aiming at the complexity and diversity of transport protocols, this paper proposes a multi-protocol data analysis method, which can parse data under various protocols, and converts it into MQTT protocol of the Internet of Things standard to realize data upload by unified protocol. Secondly, aiming at the problem of real-time reliability in protocol conversion, an asynchronous processing mechanism with breakpoint continuation capability is proposed to deal with concurrent tasks quickly, which ensures the real-time reliability of protocol conversion. Finally, on the basis of guaranteeing real-time reliability, a three-layer encryption method is proposed to realize highly secure data transmission. At the same time, The IIoT gateway architecture is implemented on hardware and software, and experiments are conducted on industrial process control equipment. The experimental results show that the proposed IIoT gateway architecture can effectively address the problem of data fusion between industrial system and cloud platform.},
  keywords = {Asynchronous processing,Cloud computing,Computer architecture,Data communication,gateway,IIoT,Industrial Internet of Things,insert,Logic gates,MQTT,Multi-protocol,Protocols,Real-time systems,Three-layer encryption},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/XJAYKJEF/9368773.html}
}

@inproceedings{zhong2019NovelUnsupervisedAnomaly,
  title = {A Novel Unsupervised Anomaly Detection for Gas Turbine Using {{Isolation Forest}}},
  booktitle = {2019 {{IEEE International Conference}} on {{Prognostics}} and {{Health Management}} ({{ICPHM}})},
  author = {Zhong, Shisheng and Fu, Song and Lin, Lin and Fu, Xuyun and Cui, Zhiquan and Wang, Rui},
  year = 2019,
  month = jun,
  pages = {1--6},
  doi = {10.1109/ICPHM.2019.8819409},
  urldate = {2025-11-14},
  abstract = {Monitoring gas turbines' health, in particular, detecting abnormal behaviors in time, is critical in ensuring gas turbine operating safety and in preventing costly unplanned maintenance. One most popular anomaly detection method is to obtain a classification-prediction model by training a classifier using the real-life data of gas turbine. The excellent detection ability of this method is attributed to enough annotated samples, especially enough annotated abnormal samples. Nevertheless, in gas turbine monitoring data, normal data is far more than abnormal data, even no abnormal data. Advanced technologies that can accurately detect the abnormal behaviors in time using the unlabeled data are in great need. Thus, a novel unsupervised anomaly detection based on Isolation Forest is investigated for gas turbine gas path anomaly detection in this paper. Specifically, the monitoring data is grouped by time series for weakening the affection of inevitable performance degradation when gas turbine operating, and then all detected by an isolation forest model with low contamination. Each detected abnormal group is detected again by an isolation forest model with high contamination for obtaining the specific abnormal flight-cycles. Using the real-life monitoring data from 8 different CFM56-7B aeroengines, the detection results show that the method based on Isolation Forest can achieve high accuracy abnormal detection under unlabeled data and small data set.},
  keywords = {anomaly detection,Anomaly detection,Contamination,Data models,engine health management,Forestry,gas turbine,Isolation Forest,Monitoring,Training,Turbines,unsupervised},
  file = {/home/kzlee/snap/zotero-snap/common/Zotero/storage/L42USJAS/8819409.html}
}
